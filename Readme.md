# 基于MNIST数据集的手写体识别

#### 一、算法选择

​	本次作业要求使用SVM算法进行进行手写体数字的识别，通过效果对比，采用了**RBF高斯核**进行模型训练。

训练环境：Python 3.9， CPU。

#### 二、训练历程

​	在两天时间内训练了四个模型，详细内容如下：

​	首先为了更好的观察数据集特征，我将下载好的train和test的image 无符号二进制文件进行处理，生成了60000 + 10000张图片。这里要吐槽一下sklearn的svm默认只能调用CPU的单核，所以训练速度很慢。

![2](https://github.com/Aaronhuang-778/SVM_Digit-Rec/blob/main/pic/2.png)

1.  SVM(RBF)模型，惩罚系数C固定为1——svm_v1.model

   - 训练时间：5min
   - 训练集：60000张图片
   - 测试集：10000张图片
   - 准确率：97.69%

2. SVM（RBF）模型，采用网格搜索自动调整参数，C的范围[0.9, 1, 0.01]——svm_v2.model

   - 训练时间：2h

   - 训练集：60000张图片
   - 测试集：10000张图片
   - 准确率：97.92%

3. SVM（RBF）模型，惩罚系数固定为1——svm_v3.model

   - 训练时间：7h

   - 训练集：360000张图片，使用了非常好用的AutoAugment模型进行数据增强，能够在15个维度上对原图进行多域增强，同时使用了增强模型中的`SVHNPolicy()`，专门增强数字图片

     论文地址：[[1805.09501v1\] AutoAugment: Learning Augmentation Policies from Data (arxiv.org)](https://arxiv.org/abs/1805.09501v1)

   - 测试集：10000张图片

   - 准确率：97.100003%

4. SVM（RBF）模型，采用网格搜索寻找最优参数，C的范围[0.8, 0.9, 1,1.1,1.2]——svm_v4.model

   - 训练时间：6h
   - 训练集：60000张图片
   - 测试集：10000张图片
   - 准确率：98.04%

上述模型就是我本次探索的全部结果，特别意外的是将训练集增强了6倍，效果反而最差，这一点起初最令人疑惑，因为之前在小数据集的图像类比赛中都能起到非常正向的影响。但是通过对数据集的观察不难发现，由于是手写数字体，本来就千姿百态，特别是4和6这两个数字很容易在潦草的情况下混淆，如果再按照往常处理图片小数据集的方法进行裁剪、投影、旋转、色度改变（最后还需要转成灰度图）等等操作，可能会出现过度调整的问题，将原本模棱两可的数字更加偏向于和自己标签相反的一边了。这样训练的模型效果适得其反。尤其在易混淆的数字之间，准确率下降很快，在数字通过训练发现数字1预测结果最好的。

最后只能说还是需要炼丹调参，效果最好，经过了数个小时的训练终于得到了突破98%的结果，也是很意外的，但是相比神经网络系列算法突破准确率99%还是有一定的差距，这也是SVM本身超平面分类的局限性所导致。

#### 三、调用测试

​	测试的时候只需要运行`model_test.py`文件即可

​	跟新文件后将训练的所有内容均上传至Github，希望和大家一起学习。在`model_test`文件当中可以直接调取main进行测试，如下所示：	

​	其中包含四个路径，因为测试文件支持图片保存路径也支持原数据集的ubyte格式读取图片，所以可以通过两种类型进行调用，注释的方法为ubyte格式测试集。

```python
model_path = "svm_v4.model"
test_ubyte_path = "dataset/t10k-images.idx3-ubyte"
label_path = "dataset/t10k-labels.idx1-ubyte"
test_img_path = "test_image/"


#svm_test(model_path, test_ubyte_path, label_path)
svm_test1(model_path, test_img_path)
```

#### 四、数据结果

以下数据可以自己生成，dataset前往MNIST官方自行下载

![3](https://github.com/Aaronhuang-778/SVM_Digit-Rec/blob/main/pic/3.png)
